kafka:
  broker:
    user: cp-kafka
    group: confluent
    config_file: /etc/kafka/server.properties
    sasl_jaas_cfg_file: /etc/kafka/kafka_server_jaas.conf
    systemd_file: /usr/lib/systemd/system/confluent-kafka.service
    systemd_override: /etc/systemd/system/confluent-kafka.service.d
    service_name: confluent-kafka
    datadir:
      - /var/lib/kafka/data
    systemd:
      enabled: yes
      state: started
    environment:
      KAFKA_HEAP_OPTS: "-Xmx1g"
    config:
      group.initial.rebalance.delay.ms: 0
      log.retention.check.interval.ms: 300000
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      num.io.threads: 16
      num.network.threads: 8
      num.partitions: 3
      num.recovery.threads.per.data.dir: 1
      offsets.topic.replication.factor: 3
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      socket.send.buffer.bytes: 102400
      transaction.state.log.min.isr: 1
      transaction.state.log.replication.factor: 3
      zookeeper.connection.timeout.ms: 6000
      metric.reporters: io.confluent.metrics.reporter.ConfluentMetricsReporter
      confluent.metrics.reporter.bootstrap.servers: "{{inventory_hostname}}:{{broker.config.port}}"
      confluent.metrics.reporter.topic.replicas: 3
      confluent.metrics.reporter.ssl.endpoint.identification.algorithm: ""
      ssl.endpoint.identification.algorithm: ""
